{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f5802f-f203-4455-9de6-f72f43040aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp toolloop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3ef65-b77e-4937-b78f-70fc3b40c61f",
   "metadata": {},
   "source": [
    "# Tool Loop\n",
    "\n",
    "The code for Claudette's tool loop should essentially work as is. We'll replicate the whole original notebook just to make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8eb7ee4-91a4-4f58-942a-ecd3d78eb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from gaspare.core import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9f6dd6-1216-4776-90f2-8910fc883cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini-2.0-flash'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models[2]\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb0680-f3bd-4fba-83b5-4d72ad22e988",
   "metadata": {},
   "source": [
    "Let's use the [same example](https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/customer_service_agent.ipynb) from Claudette's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36025e7-18aa-48ad-a313-0badce6ea107",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = {\n",
    "    \"O1\": dict(id=\"O1\", product=\"Widget A\", quantity=2, price=19.99, status=\"Shipped\"),\n",
    "    \"O2\": dict(id=\"O2\", product=\"Gadget B\", quantity=1, price=49.99, status=\"Processing\"),\n",
    "    \"O3\": dict(id=\"O3\", product=\"Gadget B\", quantity=2, price=49.99, status=\"Shipped\")}\n",
    "\n",
    "customers = {\n",
    "    \"C1\": dict(name=\"John Doe\", email=\"john@example.com\", phone=\"123-456-7890\",\n",
    "               orders=[orders['O1'], orders['O2']]),\n",
    "    \"C2\": dict(name=\"Jane Smith\", email=\"jane@example.com\", phone=\"987-654-3210\",\n",
    "               orders=[orders['O3']])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8887b19-fd70-4d9f-9089-8278445f6a34",
   "metadata": {},
   "source": [
    "As with Claudette, we do not have to create the JSON schema manually. We can use docments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b544f2ad-0e09-4466-9ae2-ada005227996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_info(\n",
    "    customer_id:str # ID of the customer\n",
    "): # Customer's name, email, phone number, and list of orders\n",
    "    \"Retrieves a customer's information and their orders based on the customer ID\"\n",
    "    print(f'- Retrieving customer {customer_id}')\n",
    "    return customers.get(customer_id, \"Customer not found\")\n",
    "\n",
    "def get_order_details(\n",
    "    order_id:str # ID of the order\n",
    "): # Order's ID, product name, quantity, price, and order status\n",
    "    \"Retrieves the details of a specific order based on the order ID\"\n",
    "    print(f'- Retrieving order {order_id}')\n",
    "    return orders.get(order_id, \"Order not found\")\n",
    "\n",
    "def cancel_order(\n",
    "    order_id:str # ID of the order to cancel\n",
    ")->bool: # True if the cancellation is successful\n",
    "    \"Cancels an order based on the provided order ID\"\n",
    "    print(f'- Cancelling order {order_id}')\n",
    "    if order_id not in orders: return False\n",
    "    orders[order_id]['status'] = 'Cancelled'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7fd0a-93b0-4c76-b8c1-1b40025642e7",
   "metadata": {},
   "source": [
    "We are ready to go. The main difference here is that we don't assign the tools to the chat itself, since otherwise Gemini becomes too eager to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ddf3f7-a1c7-4178-bf34-03c9ac2345b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_customer_info, get_order_details, cancel_order]\n",
    "chat = Chat(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4935c5-4504-4e0d-ba22-4879024e5703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<ul><li><code>get_customer_info(customer_id=C1)</code></li></ul>\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_call</code>: <ul><li><code>name</code>: get_customer_info</li><li><code>args</code>: <ul><li><b>customer_id</b>: C1</li></ul></li></ul></li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.00010187082225456833</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 147; Out: 10; Total: 157</li><li><code>automatic_function_calling_history</code>: </li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'customer_id': 'C1'}, name='get_customer_info'), function_response=None, inline_data=None, text=None)], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.00010187082225456833, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 147; Out: 10; Total: 157, automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat('Can you tell me the email address for customer C1?', tools=tools, use_afc=False)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8042fc83-48b5-4d8a-94f8-f17623088619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The email address for customer C1 is john@example.com.<br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: The email address for customer C1 is john@example.com.\n",
       "</li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -2.561106230132282e-05</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 71; Out: 15; Total: 86</li><li><code>automatic_function_calling_history</code>: </li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='The email address for customer C1 is john@example.com.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-2.561106230132282e-05, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 71; Out: 15; Total: 86, automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d35f5c-2842-4411-95f7-cd5dd66e7264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I can only cancel orders if I have the order ID. I need to get the order IDs for customer C1 first.  I will use the `get_customer_info` to retrieve the customer's information and their orders, then iterate through the orders and cancel them.<br /><br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: I can only cancel orders if I have the order ID. I need to get the order IDs for customer C1 first.  I will use the `get_customer_info` to retrieve the customer's information and their orders, then iterate through the orders and cancel them.\n",
       "\n",
       "</li></ul></details>\n",
       "<details open='true'><summary>parts[1]</summary><ul><li><code>function_call</code>: <ul><li><code>name</code>: get_customer_info</li><li><code>args</code>: <ul><li><b>customer_id</b>: C1</li></ul></li></ul></li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.07763530927545884</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 218; Out: 68; Total: 286</li><li><code>automatic_function_calling_history</code>: </li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=\"I can only cancel orders if I have the order ID. I need to get the order IDs for customer C1 first.  I will use the `get_customer_info` to retrieve the customer's information and their orders, then iterate through the orders and cancel them.\\n\\n\"), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'customer_id': 'C1'}, name='get_customer_info'), function_response=None, inline_data=None, text=None)], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.07763530927545884, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 218; Out: 68; Total: 286, automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = \"\"\"You will be provided with tools, but don't limit your answer to those tools.\n",
    "If the user query is related to some of the tools you have access to come up with a sequence of actions to achieve the goal and **execute the plan immediately**.\n",
    "\n",
    "If the user query is unrelated to the tools you have access to, answer the query using your own knowledge.\"\"\"\n",
    "\n",
    "chat = Chat(model)\n",
    "r = chat('Cancel all orders for customer C1.', tools=tools, use_afc=False, sp=sp, temp=0.)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b04e2e8-7d43-4918-88c1-07572351b938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionCall(id=None, args={'customer_id': 'C1'}, name='get_customer_info')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.function_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c44ad55-b87e-463f-b924-56ae2e35315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "@delegates(genai.chats.Chat.__call__)\n",
    "def toolloop(self:genai.chats.Chat,\n",
    "             pr, # Prompt to pass to Gemini\n",
    "             max_steps=10, # Maximum number of tool requests to loop through\n",
    "             trace_func:Optional[callable]=None, # Function to trace tool use steps (e.g `print`)\n",
    "             cont_func:Optional[callable]=noop, # Function that stops loop if returns False\n",
    "             **kwargs):\n",
    "    \"Add prompt `pr` to dialog and get a response from Gemini, automatically following up with `tool_use` messages\"\n",
    "    n_msgs = len(self.h)\n",
    "    kwargs[\"use_afc\"] = False\n",
    "    r = self(pr, **kwargs)\n",
    "    for i in range(max_steps):\n",
    "        if not r.function_calls:break\n",
    "        if trace_func: trace_func(self.h[n_msgs:]); n_msgs = len(self.h)\n",
    "        r = self(**kwargs)\n",
    "        if not (cont_func or noop)(self.h[-2]): break\n",
    "    if trace_func: trace_func(self.h[n_msgs:])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1f588c-a5e0-469e-a1a7-47bbde5b637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The email address for customer C1 is john@example.com.<br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: The email address for customer C1 is john@example.com.\n",
       "</li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.0002421900009115537</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 279; Out: 15; Total: 294</li><li><code>automatic_function_calling_history</code>: </li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='The email address for customer C1 is john@example.com.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.0002421900009115537, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 279; Out: 15; Total: 294, automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model)\n",
    "r = chat.toolloop('Tell me the email address for customer C1.', tools=tools, sp=sp, temp=0.)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfec47d8-9832-4cfa-acb5-98d86474a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n",
      "\n",
      "Message 1, Part 1:\n",
      "\n",
      "* Text *: Cancel all orders for customer C1.\n",
      "\n",
      "\n",
      "Message 2, Part 1:\n",
      "\n",
      "* Text *: I can only cancel orders if I have the order ID. I need to retrieve the customer's information first to identify their orders. After that, I can cancel each order individually.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Message 2, Part 2:\n",
      "\n",
      "* Function Call *: id=None args={'customer_id': 'C1'} name='get_customer_info'\n",
      "\n",
      "- Cancelling order O1\n",
      "- Cancelling order O2\n",
      "\n",
      "Message 1, Part 1:\n",
      "\n",
      "* Function Response *: {'name': 'John Doe', 'email': 'john@example.com', 'phone': '123-456-7890', 'orders': [{'id': 'O1', 'product': 'Widget A', 'quantity': 2, 'price': 19.99, 'status': 'Cancelled'}, {'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Cancelled'}]}\n",
      "\n",
      "\n",
      "Message 2, Part 1:\n",
      "\n",
      "* Text *: I have retrieved the customer's information. John Doe has two orders: O1 and O2. I will now cancel each order.\n",
      "\n",
      "\n",
      "\n",
      "Message 2, Part 2:\n",
      "\n",
      "* Function Call *: id=None args={'order_id': 'O1'} name='cancel_order'\n",
      "\n",
      "\n",
      "Message 2, Part 3:\n",
      "\n",
      "* Function Call *: id=None args={'order_id': 'O2'} name='cancel_order'\n",
      "\n",
      "\n",
      "Message 1, Part 1:\n",
      "\n",
      "* Function Response *: True\n",
      "\n",
      "\n",
      "Message 1, Part 2:\n",
      "\n",
      "* Function Response *: True\n",
      "\n",
      "\n",
      "Message 2, Part 1:\n",
      "\n",
      "* Text *: Both orders O1 and O2 have been cancelled successfully.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Both orders O1 and O2 have been cancelled successfully.<br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: Both orders O1 and O2 have been cancelled successfully.\n",
       "</li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.16903127156771147</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 368; Out: 13; Total: 381</li><li><code>automatic_function_calling_history</code>: </li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Both orders O1 and O2 have been cancelled successfully.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.16903127156771147, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 368; Out: 13; Total: 381, automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_msgs(msgs):\n",
    "    for n, m in enumerate(msgs):\n",
    "        for i, part in enumerate(m.parts):\n",
    "            print(f\"\\nMessage {n+1}, Part {i + 1}:\\n\")\n",
    "            c = \"* Text *: \" + part.text if part.text  else \"\" \n",
    "            c += \"* Function Call *: \" + str(part.function_call) if part.function_call else \"\"\n",
    "            c += \"* Function Response *: \" + str(part.function_response.response['result']) if part.function_response else \"\"\n",
    "            print(c)\n",
    "            print()\n",
    "\n",
    "chat = Chat(model)\n",
    "r = chat.toolloop('Cancel all orders for customer C1.', tools=tools, trace_func=print_msgs, temp=0., sp=sp)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e849776-9d40-4efc-90c1-f76670b0da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving order O1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The status of order O1 is Cancelled.<br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: The status of order O1 is Cancelled.\n",
       "</li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.02214123457670212</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 341; Out: 10; Total: 351</li><li><code>automatic_function_calling_history</code>: </li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='The status of order O1 is Cancelled.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.02214123457670212, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 341; Out: 10; Total: 351, automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.toolloop('What is the status of order O1?', tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d76978-41aa-49ca-90fa-876ceda1b125",
   "metadata": {},
   "source": [
    "## Code interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d566a6-7d9d-44fd-b446-e2c947c892b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolslm.shell import get_shell\n",
    "from fastcore.meta import delegates\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f52c860a-0f03-40e9-83aa-55fa5019e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = 'os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses'\n",
    "\n",
    "def CodeChat(model: Optional[str] = None, ask:bool=True, tools=None, **kwargs):\n",
    "    imps = 'os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses'\n",
    "    chat = Chat(model=model, **kwargs)\n",
    "    chat.ask = ask\n",
    "    chat.shell = get_shell()\n",
    "    chat.shell.run_cell('import '+ imps)\n",
    "    chat._tools = tools\n",
    "    chat._tools.append(chat.run_code)\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "83d33598-3ba8-4f30-a2e2-f3a73e706366",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def run_code(\n",
    "    self:genai.chats.Chat,\n",
    "    code:str,   # Code to execute in persistent IPython session\n",
    "): # Result of expression on last line (if exists); '#DECLINED#' if user declines request to execute\n",
    "    \"Executes python code using a persistent IPython session. It asks the user for permission before executing the code.\"\n",
    "    confirm = f'Press Enter to execute, or enter \"n\" to skip?\\n```\\n{code}\\n```\\n'\n",
    "    if input(confirm): return '#DECLINED#'\n",
    "    try: res = self.shell.run_cell(code)\n",
    "    except Exception as e: return traceback.format_exc()\n",
    "    return res.stdout if res.result is None else res.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f07da44a-96b0-4257-a864-7e3d94f3d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = f'''You are a knowledgable coding assistant assistant. \n",
    "Don't do complex calculations yourself -- create code for them.\n",
    "You always have the ability to execute code with the `run_code` tool at your disposal.\n",
    "The following modules are pre-imported for `run_code` automatically:\n",
    "\n",
    "{imps}\n",
    "\n",
    "Note that `run_code` interpreter state is *persistent* across calls. \n",
    "\n",
    "If a tool returns `#DECLINED#` report to the user that the attempt was declined and no further progress can be made.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6a6a5715-1af3-4403-b0d3-71e60aa424a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(ignored:str # Unused parameter\n",
    "            ): # Username of current user\n",
    "    \"\"\"Get the username of the user running this session\n",
    "    \n",
    "    Example: get_user()\"\"\"\n",
    "    print(\"Looking up username\")\n",
    "    return 'Miko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6f077806-0622-4c6d-bc0b-6b29f93a39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = CodeChat(model, tools=[get_user], sp=sp, ask=True, temp=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "aa8276c9-b6bc-4665-8953-40d5794411f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I can list the libraries that are already imported in the IPython environment for you. These are:<br /><br />os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses<br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: I can list the libraries that are already imported in the IPython environment for you. These are:\n",
       "\n",
       "os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\n",
       "</li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.02876930996991586</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 198; Out: 69; Total: 267</li><li><code>automatic_function_calling_history</code>: </li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I can list the libraries that are already imported in the IPython environment for you. These are:\\n\\nos, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.02876930996991586, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 198; Out: 69; Total: 267, automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is already imported in the IPython environment?\", tools=chat._tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d8924bc0-8bd9-4dcc-87fb-1c8aa90556eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Message 1, Part 1:\n",
      "\n",
      "* Text *: Create a 1-line function `checksum` for a string `s`, that multiplies together the ascii \n",
      "values of each character in `s` using `reduce`.\n",
      "\n",
      "\n",
      "Message 2, Part 1:\n",
      "\n",
      "* Text *: ```python\n",
      "def checksum(s):\n",
      "  from functools import reduce\n",
      "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
      "```\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python<br />def checksum(s):<br />  from functools import reduce<br />  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)<br />```<br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: ```python\n",
       "def checksum(s):\n",
       "  from functools import reduce\n",
       "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
       "```\n",
       "</li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.034469225189902565</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 306; Out: 44; Total: 350</li><li><code>automatic_function_calling_history</code>: </li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```python\\ndef checksum(s):\\n  from functools import reduce\\n  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\\n```\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.034469225189902565, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 306; Out: 44; Total: 350, automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = '''Create a 1-line function `checksum` for a string `s`, that multiplies together the ascii \n",
    "values of each character in `s` using `reduce`.'''\n",
    "r = chat.toolloop(pr, trace_func=print_msgs, tools=chat._tools)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9a367d7c-302e-495c-bcf8-6ea9d6919a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = chat.toolloop('Run the code in the IPython environment', tools=chat._tools, sp=sp, temp=0.6, trace_func=print_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3c2b31f4-28e1-445b-8e51-e6c687b3a3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_genconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0m_genconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Builds a GenerateContentConfigDict from call parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentConfigDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__annotations__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0m_sp\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'system_instruction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'system_instruction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sp\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0m_temp\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'temp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_temp\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mmaxtok\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"maxtok\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_output_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxtok\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop_sequences'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m:=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tools\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tools'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolify_everything\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_afc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tool_config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'function_calling_config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tool_mode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AUTO'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'function_calling_config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcc\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tool_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimagen_models\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text_only\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response_modalities'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'response_modalities'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Repos/gaspare/gaspare/core.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat.client._genconf??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "56051d66-1224-4c16-9042-e7ae80fc2de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to execute, or enter \"n\" to skip?\n",
      "```\n",
      "\n",
      "def checksum(s):\n",
      "  from functools import reduce\n",
      "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
      "\n",
      "```\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OK. I have run the code in the IPython environment. The function `checksum` is now defined.<br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: OK. I have run the code in the IPython environment. The function `checksum` is now defined.\n",
       "</li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.01952469737633415</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 264; Out: 23; Total: 287</li><li><code>automatic_function_calling_history</code>: <details open='true'><summary>automatic_function_calling_history[0]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: What is already imported in the IPython environment?</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[1]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: I can list the libraries that are already imported in the IPython environment for you. These are:\n",
       "\n",
       "os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\n",
       "</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[2]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: Create a 1-line function `checksum` for a string `s`, that multiplies together the ascii \n",
       "values of each character in `s` using `reduce`.</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[3]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: ```python\n",
       "def checksum(s):\n",
       "  from functools import reduce\n",
       "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
       "```\n",
       "</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[4]</summary><ul><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: Run the code in the IPython environment</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[5]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_call</code>: <ul><li><code>name</code>: run_code</li><li><code>args</code>: <ul><li><b>code</b>: \n",
       "def checksum(s):\n",
       "  from functools import reduce\n",
       "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
       "</li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[6]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_response</code>: <ul><li><code>name</code>: run_code</li><li><code>response</code>: <ul><li><b>result</b>: </li></ul></li></ul></li></ul></details></li></ul></details></li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='OK. I have run the code in the IPython environment. The function `checksum` is now defined.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.01952469737633415, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 264; Out: 23; Total: 287, automatic_function_calling_history=[Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='What is already imported in the IPython environment?')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I can list the libraries that are already imported in the IPython environment for you. These are:\\n\\nos, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\\n')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Create a 1-line function `checksum` for a string `s`, that multiplies together the ascii \\nvalues of each character in `s` using `reduce`.')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```python\\ndef checksum(s):\\n  from functools import reduce\\n  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\\n```\\n')], role='model'), UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Run the code in the IPython environment')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'code': '\\ndef checksum(s):\\n  from functools import reduce\\n  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\\n'}, name='run_code'), function_response=None, inline_data=None, text=None)], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='run_code', response={'result': ''}), inline_data=None, text=None)], role='user')], parsed=None)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.send_message('Run the code in the IPython environment', config={'tools': chat._tools})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3dd28f47-545f-4d02-b19c-882a0f723d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to execute, or enter \"n\" to skip?\n",
      "```\n",
      "username = default_api.get_user()\n",
      "print(username)\n",
      "\n",
      "```\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up username\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to execute, or enter \"n\" to skip?\n",
      "```\n",
      "def checksum(s):\n",
      "  from functools import reduce\n",
      "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
      "\n",
      "username = \"Miko\"\n",
      "checksum_value = checksum(username)\n",
      "print(checksum_value)\n",
      "```\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The checksum of the username \"Miko\" is 96025545.<br />\n",
       "<details><ul><li><code>candidates</code>: <details open='true'><summary>candidates[0]</summary><ul><li><code>content</code>: <ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: The checksum of the username \"Miko\" is 96025545.\n",
       "</li></ul></details></li></ul></li><li><code>avg_logprobs</code>: -0.0005424152172747112</li><li><code>finish_reason</code>: FinishReason.STOP</li></ul></details></li><li><code>model_version</code>: gemini-2.0-flash</li><li><code>usage_metadata</code>: Cached: 0; In: 881; Out: 21; Total: 902</li><li><code>automatic_function_calling_history</code>: <details open='true'><summary>automatic_function_calling_history[0]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: What is already imported in the IPython environment?</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[1]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: I can list the libraries that are already imported in the IPython environment for you. These are:\n",
       "\n",
       "os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\n",
       "</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[2]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: Create a 1-line function `checksum` for a string `s`, that multiplies together the ascii \n",
       "values of each character in `s` using `reduce`.</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[3]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: ```python\n",
       "def checksum(s):\n",
       "  from functools import reduce\n",
       "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
       "```\n",
       "</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[4]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: What is already imported in the IPython environment?</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[5]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: I can list the libraries that are already imported in the IPython environment for you. These are:\n",
       "\n",
       "os, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\n",
       "</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[6]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: Create a 1-line function `checksum` for a string `s`, that multiplies together the ascii \n",
       "values of each character in `s` using `reduce`.</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[7]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: ```python\n",
       "def checksum(s):\n",
       "  from functools import reduce\n",
       "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
       "```\n",
       "</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[8]</summary><ul><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: Run the code in the IPython environment</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[9]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_call</code>: <ul><li><code>name</code>: run_code</li><li><code>args</code>: <ul><li><b>code</b>: \n",
       "def checksum(s):\n",
       "  from functools import reduce\n",
       "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
       "</li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[10]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_response</code>: <ul><li><code>name</code>: run_code</li><li><code>response</code>: <ul><li><b>result</b>: </li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[11]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: OK. I have run the code in the IPython environment. The function `checksum` is now defined.\n",
       "</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[12]</summary><ul><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: Use it to get the checksum of the username of this session.</li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[13]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_call</code>: <ul><li><code>name</code>: run_code</li><li><code>args</code>: <ul><li><b>code</b>: username = default_api.get_user()\n",
       "print(username)\n",
       "</li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[14]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_response</code>: <ul><li><code>name</code>: run_code</li><li><code>response</code>: <ul><li><b>result</b>: \u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
       "File \u001b[0;32m<ipython-input-1-67d2f974c846>:1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m username \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_api\u001b[49m\u001b[38;5;241m.\u001b[39mget_user()\n",
       "\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(username)\n",
       "\n",
       "\u001b[0;31mNameError\u001b[0m: name 'default_api' is not defined\n",
       "</li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[15]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: I apologize, it seems I made a mistake and `default_api` was not available in the IPython environment. I will try again.\n",
       "\n",
       "</li></ul></details>\n",
       "<details open='true'><summary>parts[1]</summary><ul><li><code>function_call</code>: <ul><li><code>name</code>: get_user</li><li><code>args</code>: <ul></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[16]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_response</code>: <ul><li><code>name</code>: get_user</li><li><code>response</code>: <ul><li><b>error</b>: Failed to invoke function get_user with converted arguments {} from model returned function call argument {} because of error get_user() missing 1 required positional argument: 'ignored'</li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[17]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: I apologize again for the error. It seems I need to provide the `ignored` argument.\n",
       "</li></ul></details>\n",
       "<details open='true'><summary>parts[1]</summary><ul><li><code>function_call</code>: <ul><li><code>name</code>: get_user</li><li><code>args</code>: <ul><li><b>ignored</b>: </li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[18]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_response</code>: <ul><li><code>name</code>: get_user</li><li><code>response</code>: <ul><li><b>result</b>: Miko</li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[19]</summary><ul><li><code>role</code>: model</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>text</code>: Okay, the username is \"Miko\". Now I can calculate the checksum.\n",
       "</li></ul></details>\n",
       "<details open='true'><summary>parts[1]</summary><ul><li><code>function_call</code>: <ul><li><code>name</code>: run_code</li><li><code>args</code>: <ul><li><b>code</b>: def checksum(s):\n",
       "  from functools import reduce\n",
       "  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\n",
       "\n",
       "username = \"Miko\"\n",
       "checksum_value = checksum(username)\n",
       "print(checksum_value)</li></ul></li></ul></li></ul></details></li></ul></details>\n",
       "<details open='true'><summary>automatic_function_calling_history[20]</summary><ul><li><code>role</code>: user</li><li><code>parts</code>: <details open='true'><summary>parts[0]</summary><ul><li><code>function_response</code>: <ul><li><code>name</code>: run_code</li><li><code>response</code>: <ul><li><b>result</b>: 96025545\n",
       "</li></ul></li></ul></li></ul></details></li></ul></details></li></ul></details>"
      ],
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='The checksum of the username \"Miko\" is 96025545.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.0005424152172747112, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=Cached: 0; In: 881; Out: 21; Total: 902, automatic_function_calling_history=[Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='What is already imported in the IPython environment?')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I can list the libraries that are already imported in the IPython environment for you. These are:\\n\\nos, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\\n')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Create a 1-line function `checksum` for a string `s`, that multiplies together the ascii \\nvalues of each character in `s` using `reduce`.')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```python\\ndef checksum(s):\\n  from functools import reduce\\n  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\\n```\\n')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='What is already imported in the IPython environment?')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I can list the libraries that are already imported in the IPython environment for you. These are:\\n\\nos, warnings, time, json, re, math, collections, itertools, functools, dateutil, datetime, string, types, copy, pprint, enum, numbers, decimal, fractions, random, operator, typing, dataclasses\\n')], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Create a 1-line function `checksum` for a string `s`, that multiplies together the ascii \\nvalues of each character in `s` using `reduce`.')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='```python\\ndef checksum(s):\\n  from functools import reduce\\n  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\\n```\\n')], role='model'), UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Run the code in the IPython environment')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'code': '\\ndef checksum(s):\\n  from functools import reduce\\n  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\\n'}, name='run_code'), function_response=None, inline_data=None, text=None)], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='run_code', response={'result': ''}), inline_data=None, text=None)], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='OK. I have run the code in the IPython environment. The function `checksum` is now defined.\\n')], role='model'), UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Use it to get the checksum of the username of this session.')], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'code': 'username = default_api.get_user()\\nprint(username)\\n'}, name='run_code'), function_response=None, inline_data=None, text=None)], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='run_code', response={'result': \"\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m\\n\\x1b[0;31mNameError\\x1b[0m                                 Traceback (most recent call last)\\nFile \\x1b[0;32m<ipython-input-1-67d2f974c846>:1\\x1b[0m\\n\\x1b[0;32m----> 1\\x1b[0m username \\x1b[38;5;241m=\\x1b[39m \\x1b[43mdefault_api\\x1b[49m\\x1b[38;5;241m.\\x1b[39mget_user()\\n\\x1b[1;32m      2\\x1b[0m \\x1b[38;5;28mprint\\x1b[39m(username)\\n\\n\\x1b[0;31mNameError\\x1b[0m: name 'default_api' is not defined\\n\"}), inline_data=None, text=None)], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I apologize, it seems I made a mistake and `default_api` was not available in the IPython environment. I will try again.\\n\\n'), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={}, name='get_user'), function_response=None, inline_data=None, text=None)], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='get_user', response={'error': \"Failed to invoke function get_user with converted arguments {} from model returned function call argument {} because of error get_user() missing 1 required positional argument: 'ignored'\"}), inline_data=None, text=None)], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I apologize again for the error. It seems I need to provide the `ignored` argument.\\n'), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'ignored': ''}, name='get_user'), function_response=None, inline_data=None, text=None)], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='get_user', response={'result': 'Miko'}), inline_data=None, text=None)], role='user'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Okay, the username is \"Miko\". Now I can calculate the checksum.\\n'), Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'code': 'def checksum(s):\\n  from functools import reduce\\n  return reduce(lambda x, y: x * y, (ord(c) for c in s), 1)\\n\\nusername = \"Miko\"\\nchecksum_value = checksum(username)\\nprint(checksum_value)'}, name='run_code'), function_response=None, inline_data=None, text=None)], role='model'), Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id=None, name='run_code', response={'result': '96025545\\n'}), inline_data=None, text=None)], role='user')], parsed=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.send_message(\"Use it to get the checksum of the username of this session.\", config={'tools': chat._tools})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07159c7f-de61-4561-bb17-23a569bcdab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
