# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_Core.ipynb.

# %% auto 0
__all__ = ['all_model_types', 'thinking_models', 'imagen_models', 'vertex_models', 'models', 'pricings', 'audio_token_pricings',
           'get_repr', 'det_repr', 'usage', 'get_pricing', 'mk_part', 'is_texty', 'mk_parts', 'goog_doc', 'prep_tool']

# %% ../nbs/00_Core.ipynb 3
import os
import base64

import PIL
import mimetypes
import inspect

from typing import Union
from functools import wraps
from google import genai
from google.genai import types

from fastcore.all import *
from fastcore.docments import *



# %% ../nbs/00_Core.ipynb 4
all_model_types = {
    "gemini-2.0-flash": "llm-vertex#gemini-2.0-flash",
    "gemini-2.0-flash-001": "llm-vertex#gemini-2.0-flash",
    "gemini-2.0-pro-exp-02-05": "llm#gemini-2.0-pro",
    "gemini-2.0-flash-lite-preview-02-05": "llm#gemini-2.0-flash-lite",
    "gemini-1.5-flash": "llm-vertex#gemini-1.5-flash",
    "gemini-1.5-pro": "llm-vertex#gemini-1.5-pro",
    "gemini-1.5-pro-002": "llm-vertex#gemini-1.5-pro",
    "gemini-1.5-flash-8b": "llm#gemini-1.5-flash-8b",
    "gemini-2.0-flash-thinking-exp-01-21": "llm-thinking#gemini-2.0-flash-thinking",
    "imagen-3.0-generate-002": "imagen#imagen-3.0"
}

thinking_models = [m for m in all_model_types if "thinking" in all_model_types[m]]

imagen_models = [m for m in all_model_types if "imagen" in all_model_types[m]]

vertex_models = [m for m in all_model_types if "vertex" in all_model_types[m]]

models = [m for m in all_model_types if "llm" in all_model_types[m]]

models

# %% ../nbs/00_Core.ipynb 40
def get_repr(m, lab=""):
    """Recurisvely fetch the markdown representation of genai.types fields, wrapping lists into `<details>` blocks"""
    if hasattr(m, '_repr_markdown_'): return m._repr_markdown_()
    if is_listy(m): return "\n".join([f"<details open='true'><summary>{lab}[{i}]</summary>{get_repr(li)}</details>" for i, li in enumerate(m)])
    if isinstance(m, dict): return "<ul>" + "\n".join([f"<li><b>{i}</b>: {get_repr(li, i)}</li>" for i, li in m.items()]) + "</ul>"
    if isinstance(m, bytes): return m[:10] + b'...'
    return str(m)


# %% ../nbs/00_Core.ipynb 43
def det_repr(m): return "<ul>" + "".join(f"<li><code>{d}</code>: {get_repr(getattr(m, d), d)}</li>" for d in m.model_fields_set) + "</ul>"

# %% ../nbs/00_Core.ipynb 46
@patch
def _repr_markdown_(self: genai._common.BaseModel):
    return det_repr(self)

# %% ../nbs/00_Core.ipynb 50
@patch
def _repr_markdown_(self: genai.types.GenerateContentResponse):
    c = None
    try:
        c = self.text.replace("\n", "<br />")
    except ValueError as e:
        calls = (f"<code>{call.name}({', '.join([f'{a}={v}' for a, v in call.args.items()])})</code>" for call in self.function_calls)
        calls_repr = '\n'.join(f'<li>{c}</li>' for c in calls)
        c = f"<ul>{calls_repr}</ul>"
    dets = det_repr(self)
    return f"""{c}\n<details>{dets}</details>"""

# %% ../nbs/00_Core.ipynb 54
@patch(as_prop=True)
def html(self: types.Image):
    b64 = base64.b64encode(self.image_bytes).decode("utf-8")
    return f'<img src="data:{self.mime_type};base64,{b64}" />'


@patch
def _repr_markdown_(self: types.Image):
    return f"""<div style="width: 100px; height: auto;">{self.html}</div>

<details>
{det_repr(self)}
</details>"""

# %% ../nbs/00_Core.ipynb 56
@patch(as_prop=True)
def img(self: types.GenerateImagesResponse):
    return self.generated_images[0].image._pil_image


@patch
def _repr_markdown_(self: types.GenerateImagesResponse):
    N = len(self.generated_images)
    cols = min(N, 4)
    rows = math.ceil(N / 4)
   
    ims = "".join([f"""<div style="display: grid; 
                    width: 100%; 
                    max-width: 1000px; 
                    height: auto;
                    margin: 0 auto; 
                    grid-template-columns: {rows}fr;
                    grid-template-rows: 1ft;
                   ">{gim.image.html}</div>""" 
                   for gim in self.generated_images])
    
    
    
    i = f"""
<div style="display: grid; 
                gap: 4px; 
                width: 100%;
                height: auto;
                max-width: 1000px; 
                margin: 0 auto; 
                padding: 4px;
                grid-template-columns: repeat({cols}, 1fr);
                grid-template-rows: repeat({rows}, 1fr);
                ">

{ims}

</div>
    """
    return f"""{i}

<details>
{det_repr(self)}
</details>
"""

# %% ../nbs/00_Core.ipynb 61
def usage(inp=0,     # Number of input tokens (excluding cached)
          out=0,     # Number of output tokens
          cached=0): # Number of cached tokens
    """A quicker and simpler constructor for the Usage Metadata model"""
    return types.GenerateContentResponseUsageMetadata(cached_content_token_count=cached, 
                                                      candidates_token_count=out, 
                                                      prompt_token_count=inp + cached, 
                                                      total_token_count=inp + out + cached)

# %% ../nbs/00_Core.ipynb 65
@patch(as_prop=True)
def cached(self: types.GenerateContentResponseUsageMetadata): 
    return self.cached_content_token_count or 0

@patch(as_prop=True)
def inp(self: types.GenerateContentResponseUsageMetadata): 
    return (self.prompt_token_count - self.cached) or 0

@patch(as_prop=True)
def out(self: types.GenerateContentResponseUsageMetadata): 
    return self.candidates_token_count or 0

@patch(as_prop=True)
def total(self: types.GenerateContentResponseUsageMetadata): 
    return self.total_token_count or self.prompt_token_count + self.candidates_token_count

# %% ../nbs/00_Core.ipynb 68
@patch
def __repr__(self: types.GenerateContentResponseUsageMetadata):
    return f"Cached: {self.cached}; In: {self.inp}; Out: {self.out}; Total: {self.total}"

@patch
def _repr_markdown_(self: types.GenerateContentResponseUsageMetadata):
    return self.__repr__()

# %% ../nbs/00_Core.ipynb 72
@patch
def __add__(self: types.GenerateContentResponseUsageMetadata, other):
    cached = getattr(self, "cached", 0) + getattr(other, "cached", 0)
    return usage(self.inp + other.inp, self.out + other.out, cached)

# %% ../nbs/00_Core.ipynb 75
# $/1M input (non cached) tokens, $/1M output tokens, $/1M cached input tokens, 

pricings = {
    'gemini-2.0-flash': [0.1, 0.4, 0.025],
    'gemini-2.0-flash-lite': [0.075, 0.3, 0.01875],
    'gemini-1.5-flash_short': [0.075, 0.3, 0.01875],
    'gemini-1.5-flash_long': [0.15, 0.6, 0.0375], 
    'gemini-1.5-flash-8b_short': [0.0375, 0.15, 0.01],
    'gemini-1.5-flash-8b_long': [0.075, 0.3, 0.02],
    'gemini-1.5-pro_short': [1.25, 5., 0.3125],   
    'gemini-1.5-pro_long': [2.5, 10., 0.625],
 }


audio_token_pricings = {
    'gemini-2.0-flash': [0.7, 0.4, 0.175],
}

def get_pricing(model, prompt_tokens):
    if "-exp-" in model: return [0, 0, 0]
    suff = "_long" if prompt_tokens > 128_000 else "_short"
    m = all_model_types.get(model, "#").split("#")[-1]
    m += suff if "1.5" in m else ""
    return pricings.get(m, [0, 0, 0])


# %% ../nbs/00_Core.ipynb 78
@patch(as_prop=True)
def cost(self: types.GenerateContentResponse):
    ip, op, cp = get_pricing(self.model_version, self.usage_metadata.prompt_token_count)
    return ((self.usage_metadata.inp * ip) + (self.usage_metadata.out * op) + (self.usage_metadata.cached * cp)) / 1e6

# %% ../nbs/00_Core.ipynb 80
@patch(as_prop=True)
def cost(self: types.GenerateImagesResponse): return 0.03 * len(self.generated_images)

# %% ../nbs/00_Core.ipynb 86
def mk_part(inp: Union[str, Path, types.Part, types.File, PIL.Image.Image], c: genai.Client|None=None):
    "Turns an input fragment into a multimedia `Part` to be sent to a Gemini model"
    api_client = c or genai.Client(api_key=os.environ["GEMINI_API_KEY"])
    if isinstance(inp, (types.Part, types.File, PIL.Image.Image)): return inp
    p_inp = Path(inp)
    if p_inp.exists():
        mt = mimetypes.guess_type(p_inp)[0]
        if mt.split("/")[0] == "image": return types.Part.from_bytes(data=p_inp.read_bytes(), mime_type=mt)
        return api_client.files.upload(file=p_inp)
    return types.Part.from_text(text=inp)
        

# %% ../nbs/00_Core.ipynb 95
def is_texty(o): return isinstance(o, str) or (isinstance(o, types.Part) and bool(o.text))

def mk_parts(inps, c=None):
    cts = L(inps).map(mk_part, c=c) if inps else L(" ")
    return list(cts) if len(cts) > 1 or is_texty(cts[0]) else list(cts + [" "])

# %% ../nbs/00_Core.ipynb 103
@patch(as_prop=True)
def use(self: genai.Client): return getattr(self, "_u", usage())

@patch(as_prop=True)
def cost(self: genai.Client): return getattr(self, "_cost", 0)

@patch
def _r(self: genai.Client, r):
    self.result = r
    self._u = self.use + getattr(r, "usage_metadata", usage())
    self._cost = self.cost + r.cost
    return r

# %% ../nbs/00_Core.ipynb 110
@patch(as_prop=True)
def _parts(self: types.GenerateContentResponse): return nested_idx(self, "candidates", 0, "content", "parts") or []
    

@patch
def _stream(self: genai.Client, s):
    all_parts = []
    for r in s:
        all_parts.extend(r._parts)
        yield r.text
    r.candidates[0].content.parts = all_parts
    self._r(r)

# %% ../nbs/00_Core.ipynb 121
def _googlify_docs(fdoc:str,                  # Docstring of a function
                    argdescs: dict|None=None, # Dict of arg:docment of the arguments of the function
                    retd: str|None=None       # Return docoment of the function
                   )-> str: # The function docstring following Google style guide
    """Turns a function docment and docstring into a docstrings that function """
    if argdescs: fdoc += "\n\nArgs:\n"  + "\n".join([f"    {p}: {desc}" for p, desc in argdescs.items()])
    if retd: fdoc += f"\n\nReturns:\n    {retd}"
    return fdoc

def goog_doc(f:callable # A docment style function
            )->str:     # Google style docstring
    """Builds the docstring for a docment style function following Google style guide"""
    fdoc = f.__doc__
    args = {par: doc for par, doc in docments(f, returns=False).items() if doc is not None}
    retd = docments(f, full=True, returns=True)['return']['docment']
    return _googlify_docs(fdoc, args, retd)
    

# %% ../nbs/00_Core.ipynb 124
def _geminify(f: callable) -> callable:
    """Makes a function suitable to be turned into a function declaration: 
    infers argument types from default values and removes the values from the signature"""
    docs = docments(f, full=True)
    new_params = [inspect.Parameter(name=n,
                                    kind=inspect.Parameter.POSITIONAL_OR_KEYWORD,
                                    annotation=i.anno) for n, i in docs.items() if n != 'return']
    @wraps(f)
    def wrapper(*args, **kwargs):
        return f(*args, **kwargs)
    
    wrapper.__signature__ = inspect.Signature(new_params, return_annotation=docs['return']['anno'])
    wrapper.__annotations__ = {n: i['anno'] for n, i in docs.items() if n != 'return'}
    return wrapper


def prep_tool(f:callable, # The function to be passed to the LLM
             as_decl:bool=False,  # Return an enriched genai.types.FunctionDeclaration?
             googlify_docstring:bool=True): # Use docments to rewrite the docstring following Google Style Guide? 
    """Optimizes for function calling with the Gemini api. Best suited for docments style functions."""
    _f = _geminify(f)
    if googlify_docstring: _f.__doc__ = goog_doc(_f)
    if not as_decl: return _f
    f_decl = types.FunctionDeclaration.from_callable_with_api_option(callable=_f, api_option='GEMINI_API')
    for par, desc in docments(_f, returns=False).items():
        if desc: f_decl.parameters.properties[par].description = desc
    required_params = [p for p, d in docments(f, full=True, returns=False).items() if d['default'] == inspect._empty]
    f_decl.parameters.required = required_params
    return f_decl
